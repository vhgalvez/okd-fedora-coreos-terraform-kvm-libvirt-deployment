variant: flatcar
version: 1.1.0

ignition:
  version: 3.4.0

passwd:
  users:
    - name: core
      shell: /bin/bash
      sudo: ["ALL=(ALL) NOPASSWD:ALL"]
      groups: [adm, wheel]
      lock_passwd: false
      ssh_authorized_keys:
        - ${ssh_keys}
    - name: root
      shell: /bin/bash
      ssh_authorized_keys:
        - ${ssh_keys}
      password_hash: "$6$hNh1nwO5OWWct4aZ$OoeAkQ4gKNBnGYK0ECi8saBMbUNeQRMICcOPYEu1bFuj9Axt4Rh6EnGba07xtIsGNt2wP9SsPlz543gfJww11/"

storage:
  directories:
    - path: /etc/kubernetes/pki
      filesystem: root
      mode: 0755
    - path: /opt/bin
      filesystem: root
      mode: 0755
    - path: /etc/cni/net.d
      filesystem: root
      mode: 0755
    - path: /var/lib/etcd
      filesystem: root
      mode: 0755

  files:
    - path: /etc/hostname
      filesystem: root
      mode: 0644
      contents:
        inline: ${host_name}

    - path: /etc/kubernetes/pki/ca.crt
      filesystem: root
      mode: 0644
      contents:
        inline: ""

    - path: /etc/kubernetes/pki/kubelet.crt
      filesystem: root
      mode: 0644
      contents:
        inline: ""

    - path: /etc/kubernetes/pki/kubelet.key
      filesystem: root
      mode: 0600
      contents:
        inline: ""

    - path: /etc/kubernetes/pki/apiserver.crt
      filesystem: root
      mode: 0644
      contents:
        inline: ""

    - path: /etc/kubernetes/pki/apiserver.key
      filesystem: root
      mode: 0600
      contents:
        inline: ""

    - path: /etc/kubernetes/pki/sa.pub
      filesystem: root
      mode: 0644
      contents:
        inline: ""

    - path: /etc/kubernetes/pki/sa.key
      filesystem: root
      mode: 0600
      contents:
        inline: ""

    - path: /etc/kubernetes/pki/etcd/etcd.crt
      filesystem: root
      mode: 0644
      contents:
        inline: ""

    - path: /etc/kubernetes/pki/etcd/etcd.key
      filesystem: root
      mode: 0600
      contents:
        inline: ""

    - path: /etc/kubernetes/pki/etcd/ca.crt
      filesystem: root
      mode: 0644
      contents:
        inline: ""

    - path: /etc/kubernetes/pki/apiserver-etcd-client.crt
      filesystem: root
      mode: 0644
      contents:
        inline: ""

    - path: /etc/kubernetes/pki/apiserver-etcd-client.key
      filesystem: root
      mode: 0600
      contents:
        inline: ""

files:
    - path: /etc/hostname
      filesystem: root
      mode: 0644
      contents:
        inline: ${host_name}

    - path: /etc/kubernetes/kubelet.conf
      filesystem: root
      mode: 0644
      contents:
        inline: |
          apiVersion: v1
          kind: Config
          clusters:
          - cluster:
              certificate-authority: /etc/kubernetes/pki/ca.crt
              server: https://${ip}:6443
            name: local
          contexts:
          - context:
              cluster: local
              user: kubelet
            name: local
          current-context: local
          users:
          - name: kubelet
            user:
              client-certificate: /etc/kubernetes/pki/kubelet.crt
              client-key: /etc/kubernetes/pki/kubelet.key

    - path: /etc/kubernetes/kubelet-config.yaml
      filesystem: root
      mode: 0644
      contents:
        inline: |
          kind: KubeletConfiguration
          apiVersion: kubelet.config.k8s.io/v1beta1
          authentication:
            x509:
              clientCAFile: "/etc/kubernetes/pki/ca.crt"
          authorization:
            mode: Webhook
          serverTLSBootstrap: true
          tlsCertFile: "/etc/kubernetes/pki/kubelet.crt"
          tlsPrivateKeyFile: "/etc/kubernetes/pki/kubelet.key"
          cgroupDriver: systemd
          runtimeRequestTimeout: "15m"
          containerRuntimeEndpoint: "unix:///var/run/crio/crio.sock"

    - path: /etc/systemd/network/10-eth0.network
      filesystem: root
      mode: 0644
      contents:
        inline: |
          [Match]
          Name=eth0

          [Network]
          Address=${ip}/24
          Gateway=${gateway}
          DNS=${dns1}
          DNS=${dns2}

    - path: /etc/tmpfiles.d/hosts.conf
      filesystem: root
      mode: 0644
      contents:
        inline: |
          f /etc/hosts 0644 - - - -
          127.0.0.1   localhost
          ::1         localhost
          ${ip}  ${host_name} ${node_name}

    - path: /run/systemd/resolve/resolv.conf
      filesystem: root
      mode: 0644
      contents:
        inline: |
          nameserver ${dns1}
          nameserver ${dns2}

    - path: /etc/tmpfiles.d/resolv.conf
      filesystem: root
      mode: 0644
      contents:
        inline: |
          L /etc/resolv.conf - - - - /run/systemd/resolve/resolv.conf

    - path: /home/core/install-components.sh
      filesystem: root
      mode: 0755
      contents:
        inline: |
          #!/bin/bash
          set -euo pipefail
          exec > /var/log/install-components.log 2>&1

          # Crear directorio para binarios
          sudo mkdir -p /opt/bin

          # Descargar e Instalar el Instalador de OKD
          wget https://github.com/okd-project/okd/releases/download/4.12.0-0.okd-2023-03-18-084815/openshift-install-linux-4.12.0-0.okd-2023-03-18-084815.tar.gz
          tar -xzvf openshift-install-linux-4.12.0-0.okd-2023-03-18-084815.tar.gz
          sudo mv openshift-install /opt/bin/
          sudo chmod +x /opt/bin/openshift-install
          rm -rf openshift-install-linux-4.12.0-0.okd-2023-03-18-084815.tar.gz

          # Instalar kube-proxy
          curl -L -o /tmp/kube-proxy https://dl.k8s.io/release/v1.21.0/bin/linux/amd64/kube-proxy
          sudo mv /tmp/kube-proxy /opt/bin/kube-proxy
          sudo chmod +x /opt/bin/kube-proxy

          # Instalar etcd
          curl -L -o /tmp/etcd.tar.gz https://github.com/etcd-io/etcd/releases/download/v3.4.13/etcd-v3.4.13-linux-amd64.tar.gz
          tar -xzf /tmp/etcd.tar.gz -C /tmp
          sudo mv /tmp/etcd-v3.4.13-linux-amd64/etcd /opt/bin/etcd
          sudo chmod +x /opt/bin/etcd
          sudo rm -rf /tmp/etcd.tar.gz /tmp/etcd-v3.4.13-linux-amd64

          # Instalar kube-apiserver
          curl -L -o /tmp/kube-apiserver https://dl.k8s.io/release/v1.21.0/bin/linux/amd64/kube-apiserver
          sudo mv /tmp/kube-apiserver /opt/bin/kube-apiserver
          sudo chmod +x /opt/bin/kube-apiserver

          # Instalar kube-controller-manager
          curl -L -o /tmp/kube-controller-manager https://dl.k8s.io/release/v1.21.0/bin/linux/amd64/kube-controller-manager
          sudo mv /tmp/kube-controller-manager /opt/bin/kube-controller-manager
          sudo chmod +x /opt/bin/kube-controller-manager

          # Instalar kube-scheduler
          curl -L -o /tmp/kube-scheduler https://dl.k8s.io/release/v1.21.0/bin/linux/amd64/kube-scheduler
          sudo mv /tmp/kube-scheduler /opt/bin/kube-scheduler
          sudo chmod +x /opt/bin/kube-scheduler

          # Instalar kubelet
          curl -L -o /opt/bin/kubelet https://storage.googleapis.com/kubernetes-release/release/v1.21.0/bin/linux/amd64/kubelet
          sudo chmod +x /opt/bin/kubelet

          # Instalar oc (OpenShift Client)
          curl -L -o /tmp/oc.tar.gz https://mirror.openshift.com/pub/openshift-v4/clients/oc/latest/linux/oc.tar.gz
          tar -xzf /tmp/oc.tar.gz -C /tmp
          sudo mv /tmp/oc /opt/bin/oc
          sudo chmod +x /opt/bin/oc
          sudo rm -rf /tmp/oc.tar.gz

          # Instalar CRI-O
          sudo wget -O /tmp/crio.tar.gz https://storage.googleapis.com/cri-o/artifacts/cri-o.amd64.v1.30.3.tar.gz
          sudo mkdir -p /tmp/crio
          sudo tar -xzf /tmp/crio.tar.gz -C /tmp/crio
          sudo mkdir -p /opt/bin/crio
          sudo mv /tmp/crio/cri-o/bin/* /opt/bin/crio/
          sudo chmod +x /opt/bin/crio/*
          /opt/bin/crio/crio --version

          # Descargar conmon
          wget https://github.com/containers/conmon/releases/download/v2.1.12/conmon.amd64
          sudo mv conmon.amd64 /opt/bin/crio/conmon
          sudo chmod +x /opt/bin/crio/conmon

          # Descargar e instalar los plugins de CNI
          curl -L -o /tmp/cni-plugins.tgz https://github.com/containernetworking/plugins/releases/download/v0.9.1/cni-plugins-linux-amd64-v0.9.1.tgz
          sudo mkdir -p /opt/cni/bin
          sudo tar -xzf /tmp/cni-plugins.tgz -C /opt/cni/bin
          sudo rm -rf /tmp/cni-plugins.tgz

          # Crear configuraci√≥n de CRI-O
          sudo mkdir -p /etc/crio
          cat <<EOF | sudo tee /etc/crio/crio.conf
          [crio]
          log_level = "debug"
          root = "/var/lib/crio"
          runroot = "/var/run/crio"
          log_dir = "/var/log/crio/pods"
          version_file = "/var/run/crio/version"
          clean_shutdown_file = "/var/lib/crio/clean.shutdown"

          [crio.api]
          listen = "/var/run/crio/crio.sock"
          stream_address = "127.0.0.1"
          stream_port = "0"
          grpc_max_send_msg_size = 83886080
          grpc_max_recv_msg_size = 83886080

          [crio.runtime]
          default_runtime = "runc"
          no_pivot = false
          decryption_keys_path = "/etc/crio/keys/"
          cgroup_manager = "systemd"
          drop_infra_ctr = true
          infra_ctr_cpuset = ""
          shared_cpuset = ""
          namespaces_dir = "/var/run"
          enable_criu_support = true
          pinns_path = "/opt/bin/crio/pinns"
          conmon = "/opt/bin/crio/conmon"

          [crio.runtime.runtimes.runc]
          runtime_path = "/opt/bin/crio/crio-runc"
          runtime_type = "oci"
          runtime_root = "/run/runc"

          [crio.image]
          pause_image = "k8s.gcr.io/pause:3.2"
          image_volumes = "mkdir"

          [crio.network]
          network_dir = "/etc/cni/net.d/"
          plugin_dirs = ["/opt/cni/bin/"]
          EOF

          # Crear servicio systemd para CRI-O
          sudo mkdir -p /etc/systemd/system/
          cat <<EOF | sudo tee /etc/systemd/system/crio.service
          [Unit]
          Description=CRI-O container runtime
          After=network.target

          [Service]
          Type=notify
          ExecStart=/opt/bin/crio/crio
          Environment="PATH=/opt/bin/crio:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
          Restart=always
          RestartSec=5
          LimitNOFILE=65536
          LimitNPROC=4096

          [Install]
          WantedBy=multi-user.target
          EOF

          # Crear servicio systemd para kube-proxy
          sudo tee /etc/systemd/system/kube-proxy.service > /dev/null <<EOF
          [Unit]
          Description=Kubernetes Kube-Proxy
          After=network.target

          [Service]
          ExecStart=/opt/bin/kube-proxy --config=/etc/kubernetes/kube-proxy-config.yaml
          Restart=always
          RestartSec=5

          [Install]
          WantedBy=multi-user.target
          EOF

          # Recargar systemd y activar servicios
          sudo systemctl daemon-reload
          sudo systemctl enable kubelet
          sudo systemctl start kubelet
          sudo systemctl enable crio
          sudo systemctl start crio
          sudo systemctl enable kube-proxy
          sudo systemctl start kube-proxy




    - path: /etc/kubernetes/kubelet.conf
      filesystem: root
      mode: 0644
      contents:
        inline: |
          apiVersion: v1
          kind: Config
          clusters:
          - cluster:
              certificate-authority: /etc/kubernetes/pki/ca.crt
              server: https://${ip}:6443
            name: local
          contexts:
          - context:
              cluster: local
              user: kubelet
            name: local
          current-context: local
          users:
          - name: kubelet
            user:
              client-certificate: /etc/kubernetes/pki/kubelet.crt
              client-key: /etc/kubernetes/pki/kubelet.key

    - path: /etc/kubernetes/kubelet-config.yaml
      filesystem: root
      mode: 0644
      contents:
        inline: |
          kind: KubeletConfiguration
          apiVersion: kubelet.config.k8s.io/v1beta1
          authentication:
            x509:
              clientCAFile: "/etc/kubernetes/pki/ca.crt"
          authorization:
            mode: Webhook
          serverTLSBootstrap: true
          tlsCertFile: "/etc/kubernetes/pki/kubelet.crt"
          tlsPrivateKeyFile: "/etc/kubernetes/pki/kubelet.key"
          cgroupDriver: systemd
          runtimeRequestTimeout: "15m"
          containerRuntimeEndpoint: "unix:///var/run/crio/crio.sock"

    - path: /etc/kubernetes/scheduler.conf
      filesystem: root
      mode: 0644
      contents:
        inline: |
          apiVersion: v1
          clusters:
          - cluster:
              certificate-authority: /etc/kubernetes/pki/ca.crt
              server: https://127.0.0.1:6443
            name: local
          contexts:
          - context:
              cluster: local
              user: system:kube-scheduler
            name: system:kube-scheduler@local
          current-context: system:kube-scheduler@local
          kind: Config
          preferences: {}
          users:
          - name: system:kube-scheduler
            user:
              client-certificate: /etc/kubernetes/pki/scheduler.crt
              client-key: /etc/kubernetes/pki/scheduler.key

       - path: /etc/kubernetes/manifests/kube-apiserver.yaml
      filesystem: root
      mode: 0644
      contents:
        inline: |
          apiVersion: v1
          kind: Pod
          metadata:
            name: kube-apiserver
            namespace: kube-system
          spec:
            containers:
            - name: kube-apiserver
              image: k8s.gcr.io/kube-apiserver:v1.21.0
              command:
              - kube-apiserver
              - --advertise-address=${ip}
              - --allow-privileged=true
              - --authorization-mode=Node,RBAC
              - --client-ca-file=/etc/kubernetes/pki/ca.crt
              - --enable-admission-plugins=NodeRestriction
              - --enable-bootstrap-token-auth=true
              - --etcd-servers=https://127.0.0.1:2379
              - --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt
              - --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt
              - --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key
              - --kubelet-client-certificate=/etc/kubernetes/pki/apiserver.crt
              - --kubelet-client-key=/etc/kubernetes/pki/apiserver.key
              - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
              - --service-cluster-ip-range=${service_cidr}
              - --tls-cert-file=/etc/kubernetes/pki/apiserver.crt
              - --tls-private-key-file=/etc/kubernetes/pki/apiserver.key
              volumeMounts:
              - mountPath: /etc/kubernetes/pki
                name: pki
                readOnly: true
            volumes:
            - name: pki
              hostPath:
                path: /etc/kubernetes/pki
    - path: /etc/kubernetes/manifests/kube-scheduler.yaml
      filesystem: root
      mode: 0644
      contents:
        inline: |
          apiVersion: v1
          kind: Pod
          metadata:
            name: kube-scheduler
            namespace: kube-system
          spec:
            containers:
            - name: kube-scheduler
              image: k8s.gcr.io/kube-scheduler:v1.21.0
              command:
              - kube-scheduler
              - --bind-address=127.0.0.1
              - --kubeconfig=/etc/kubernetes/scheduler.conf
              volumeMounts:
              - mountPath: /etc/kubernetes
                name: kubeconfig
                readOnly: true
            volumes:
            - name: kubeconfig
              hostPath:
                path: /etc/kubernetes

    - path: /etc/kubernetes/manifests/etcd.yaml
      filesystem: root
      mode: 0644
      contents:
        inline: |
          apiVersion: v1
          kind: Pod
          metadata:
            name: etcd
            namespace: kube-system
          spec:
            containers:
            - name: etcd
              image: k8s.gcr.io/etcd:v3.4.13-0
              command:
              - etcd
              - --advertise-client-urls=https://127.0.0.1:2379
              - --cert-file=/etc/kubernetes/pki/etcd/etcd.crt
              - --key-file=/etc/kubernetes/pki/etcd/etcd.key
              - --client-cert-auth=true
              - --data-dir=/var/lib/etcd
              - --initial-advertise-peer-urls=https://127.0.0.1:2380
              - --initial-cluster=default=https://127.0.0.1:2380
              - --listen-client-urls=https://127.0.0.1:2379
              - --listen-peer-urls=https://127.0.0.1:2380
              - --peer-cert-file=/etc/kubernetes/pki/etcd/etcd.crt
              - --peer-key-file=/etc/kubernetes/pki/etcd/etcd.key
              - --peer-client-cert-auth=true
              - --peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt
              - --trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt
              volumeMounts:
              - mountPath: /etc/kubernetes/pki/etcd
                name: pki
                readOnly: true
              - mountPath: /var/lib/etcd
                name: etcd-data
            volumes:
            - name: pki
              hostPath:
                path: /etc/kubernetes/pki/etcd
            - name: etcd-data
              hostPath:
                path: /var/lib/etcd

    - path: /etc/systemd/system/etcd.service
      filesystem: root
      mode: 0644
      contents:
        inline: |
          [Unit]
          Description=etcd - Highly-available key value store
          Documentation=https://etcd.io/docs/
          After=network.target

          [Service]
          ExecStart=/opt/bin/etcd \\
            --name etcd0 \\
            --cert-file=/etc/kubernetes/pki/etcd/etcd.crt \\
            --key-file=/etc/kubernetes/pki/etcd/etcd.key \\
            --peer-cert-file=/etc/kubernetes/pki/etcd/etcd.crt \\
            --peer-key-file=/etc/kubernetes/pki/etcd/etcd.key \\
            --trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt \\
            --peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt \\
            --initial-advertise-peer-urls=https://127.0.0.1:2380 \\
            --listen-peer-urls=https://127.0.0.1:2380 \\
            --listen-client-urls=https://127.0.0.1:2379 \\
            --advertise-client-urls=https://127.0.0.1:2379 \\
            --data-dir=/var/lib/etcd \\
            --initial-cluster=etcd0=https://127.0.0.1:2380 \\
            --initial-cluster-token etcd-cluster-1 \\
            --initial-cluster-state new
          Restart=always
          RestartSec=5
          LimitNOFILE=40000

          [Install]
          WantedBy=multi-user.target

systemd:
  units:
    - name: apply-network-routes.service
      enabled: true
      contents: |
        [Unit]
        Description=Apply custom network routes
        After=network-online.target
        Wants=network-online.target

        [Service]
        Type=oneshot
        ExecStart=/usr/bin/systemctl restart systemd-networkd.service
        RemainAfterExit=true

        [Install]
        WantedBy=multi-user.target

    - name: set-hosts.service
      enabled: true
      contents: |
        [Unit]
        Description=Set /etc/hosts file
        After=network.target

        [Service]
        Type=oneshot
        ExecStart=/bin/bash -c 'echo "127.0.0.1   localhost" > /etc/hosts; echo "::1         localhost" >> /etc/hosts; echo "${ip}  ${host_name} ${node_name}" >> /etc/hosts'
        RemainAfterExit=true

        [Install]
        WantedBy=multi-user.target

    - name: download-certificates.service
      enabled: true
      contents: |
        [Unit]
        Description=Download Kubernetes Certificates
        After=network-online.target
        Wants=network-online.target

        [Service]
        Type=oneshot
        ExecStart=/bin/bash -c 'curl -o /etc/kubernetes/pki/ca.crt http://10.17.3.14/shared/ca/ca.crt && \
                                curl -o /etc/kubernetes/pki/kubelet.crt http://10.17.3.14/${node_name}/kubelet/kubelet.crt && \
                                curl -o /etc/kubernetes/pki/kubelet.key http://10.17.3.14/${node_name}/kubelet/kubelet.key && \
                                curl -o /etc/kubernetes/pki/apiserver.crt http://10.17.3.14/shared/apiserver/apiserver.crt && \
                                curl -o /etc/kubernetes/pki/apiserver.key http://10.17.3.14/shared/apiserver/apiserver.key && \
                                curl -o /etc/kubernetes/pki/sa.pub http://10.17.3.14/shared/sa/sa.pub && \
                                curl -o /etc/kubernetes/pki/sa.key http://10.17.3.14/shared/sa/sa.key && \
                                curl -o /etc/kubernetes/pki/etcd/etcd.crt http://10.17.3.14/shared/etcd/etcd.crt && \
                                curl -o /etc/kubernetes/pki/etcd/etcd.key http://10.17.3.14/shared/etcd/etcd.key && \
                                curl -o /etc/kubernetes/pki/etcd/ca.crt http://10.17.3.14/shared/etcd/ca.crt && \
                                curl -o /etc/kubernetes/pki/apiserver-etcd-client.crt http://10.17.3.14/shared/apiserver-etcd-client/apiserver-etcd-client.crt && \
                                curl -o /etc/kubernetes/pki/apiserver-etcd-client.key http://10.17.3.14/shared/apiserver-etcd-client/apiserver-etcd-client.key'
        RemainAfterExit=true

        [Install]
        WantedBy=multi-user.target

    - name: crio.service
      enabled: true

    - name: install-components.service
      enabled: true
      contents: |
        [Unit]
        Description=Install Kubernetes components
        After=download-certificates.service
        Wants=download-certificates.service

        [Service]
        Type=oneshot
        ExecStart=/bin/bash /home/core/install-components.sh
        RemainAfterExit=true

        [Install]
        WantedBy=multi-user.target

    - name: kube-apiserver.service
      enabled: true
      contents: |
        [Unit]
        Description=Kubernetes API Server
        After=install-components.service
        Wants=install-components.service

        [Service]
        ExecStartPre=/bin/sleep 10
        ExecStart=/opt/bin/kube-apiserver --config=/etc/kubernetes/manifests/kube-apiserver.yaml
        Restart=always
        RestartSec=10

        [Install]
        WantedBy=multi-user.target

    - name: kube-controller-manager.service
      enabled: true
      contents: |
        [Unit]
        Description=Kubernetes Controller Manager
        After=kube-apiserver.service
        Wants=kube-apiserver.service

        [Service]
        ExecStartPreHere‚Äôs the completion of the `kube-controller-manager.service` unit and the overall `machine-bootstrap-config.yaml.tmpl` template:

```yaml
        ExecStartPre=/bin/sleep 10
        ExecStart=/opt/bin/kube-controller-manager --config=/etc/kubernetes/manifests/kube-controller-manager.yaml
        Restart=always
        RestartSec=10

        [Install]
        WantedBy=multi-user.target

    - name: kube-scheduler.service
      enabled: true
      contents: |
        [Unit]
        Description=Kubernetes Scheduler
        After=kube-controller-manager.service
        Wants=kube-controller-manager.service

        [Service]
        ExecStartPre=/bin/sleep 10
        ExecStart=/opt/bin/kube-scheduler --config=/etc/kubernetes/manifests/kube-scheduler.yaml
        Restart=always
        RestartSec=10

        [Install]
        WantedBy=multi-user.target

    - name: kubelet.service
      enabled: true
      contents: |
        [Unit]
        Description=kubelet: The Kubernetes Node Agent
        Documentation=https://kubernetes.io/docs/
        Wants=crio.service
        After=crio.service

        [Service]
        ExecStart=/opt/bin/kubelet \
          --kubeconfig=/etc/kubernetes/kubelet.conf \
          --config=/etc/kubernetes/kubelet-config.yaml \
          --container-runtime=remote \
          --container-runtime-endpoint=unix:///var/run/crio/crio.sock \
          --runtime-request-timeout=15m \
          --image-gc-high-threshold=80 \
          --image-gc-low-threshold=40 \
          --enforce-node-allocatable=cpu,memory \
          --fail-swap-on=false \
          --cgroup-driver=systemd \
          --network-plugin=cni \
          --cni-bin-dir=/opt/cni/bin \
          --cni-conf-dir=/etc/cni/net.d \
          --pod-infra-container-image=k8s.gcr.io/pause:3.1 \
          --v=2
        Restart=on-failure

        [Install]
        WantedBy=multi-user.target